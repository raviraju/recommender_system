{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4710, 10) 942\n",
      "(4710, 10) 942\n",
      "(4710, 10) 942\n",
      "(4710, 10) 942\n",
      "(4710, 10) 942\n",
      "(4710, 10) 942\n",
      "(4710, 10) 942\n",
      "(4710, 10) 942\n",
      "(4705, 10) 941\n",
      "(4705, 10) 941\n"
     ]
    }
   ],
   "source": [
    "# no_of_kfolds = 10\n",
    "\n",
    "# #load_kfold_dfs,all_dfs\n",
    "# #training_all_dfs = pd.DataFrame()\n",
    "# training_kfold_dfs = dict()\n",
    "# for kfold in range(1, no_of_kfolds+1):\n",
    "#     df = pd.read_csv('hybrid_recommender/training_data/combined_predictions_' + str(kfold) + '.csv')\n",
    "#     training_kfold_dfs[kfold] = df\n",
    "#     #training_all_dfs = training_all_dfs.append(df)\n",
    "#     print(training_kfold_dfs[kfold].shape)\n",
    "# #print(training_all_dfs.shape)\n",
    "# #training_all_dfs.to_csv('hybrid_recommender/training_data/all_combined_predictions.csv', index=False)\n",
    "\n",
    "\n",
    "# #testing_all_dfs = pd.DataFrame()\n",
    "# testing_kfold_dfs = dict()\n",
    "# for kfold in range(1, no_of_kfolds+1):\n",
    "#     df = pd.read_csv('hybrid_recommender/testing_data/combined_predictions_' + str(kfold) + '.csv')\n",
    "#     testing_kfold_dfs[kfold] = df\n",
    "#     #testing_all_dfs = testing_all_dfs.append(df)\n",
    "#     print(testing_kfold_dfs[kfold].shape)\n",
    "# #print(testing_all_dfs.shape)\n",
    "# #testing_all_dfs.to_csv('hybrid_recommender/testing_data/all_combined_predictions.csv', index=False)\n",
    "\n",
    "no_of_kfolds = 10\n",
    "kfold_dfs = dict()\n",
    "for kfold in range(1, no_of_kfolds+1):\n",
    "    df = pd.read_csv('hybrid_recommender/combined_predictions_' + str(kfold) + '.csv')\n",
    "    kfold_dfs[kfold] = df\n",
    "    print(kfold_dfs[kfold].shape, kfold_dfs[kfold]['uid'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "features = ['BaselineOnly_SGD_Tuned_est',\n",
    "            'Knn_UserBased_ZScore_MSD_Tuned_est',\n",
    "            'Knn_ItemBased_ZScore_MSD_Tuned_est',\n",
    "            'Knn_UserBased_Baseline_SGD_Tuned_est',\n",
    "            'Knn_ItemBased_Baseline_SGD_Tuned_est', \n",
    "            'SVD_biased_Tuned_est',\n",
    "            'SVDpp_biased_Tuned_est']\n",
    "target = 'r_ui'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prediction_metrics(y_true, y_pred):\n",
    "    metrics = dict()\n",
    "    metrics['r2_score'] = r2_score(y_true, y_pred)\n",
    "    metrics['mean_absolute_error'] = mean_absolute_error(y_true, y_pred)\n",
    "    metrics['rmse'] = sqrt(mean_squared_error(y_true, y_pred))\n",
    "    return metrics\n",
    "\n",
    "def get_avg_test_metrics(kfold_test_metrics):\n",
    "    metrics = dict()\n",
    "    metrics['r2_score'] = []\n",
    "    metrics['mean_absolute_error'] = []\n",
    "    metrics['rmse'] = []\n",
    "    \n",
    "    for test_metrics in kfold_test_metrics:\n",
    "        metrics['r2_score'].append(test_metrics['r2_score'])\n",
    "        metrics['mean_absolute_error'].append(test_metrics['mean_absolute_error'])\n",
    "        metrics['rmse'].append(test_metrics['rmse'])\n",
    "    #print(metrics)\n",
    "    avg_metrics = dict()\n",
    "    avg_metrics['r2_score'] = round(np.mean(metrics['r2_score']), 4)\n",
    "    avg_metrics['mean_absolute_error'] = round(np.mean(metrics['mean_absolute_error']), 4)\n",
    "    avg_metrics['rmse'] = round(np.mean(metrics['rmse']), 4)\n",
    "    return avg_metrics\n",
    "\n",
    "def get_avg_metrics(estimator, kfold_dfs):\n",
    "    #print(estimator)\n",
    "    kfold_test_metrics = []\n",
    "    for kfold in range(1, no_of_kfolds+1):\n",
    "        #print('*'*40)\n",
    "        #print('kfold_', str(kfold))\n",
    "        train_df = pd.DataFrame()\n",
    "        test_df = pd.DataFrame()\n",
    "        for kfold_id, df in kfold_dfs.items():\n",
    "            if kfold == kfold_id:\n",
    "                test_df = df\n",
    "            else:\n",
    "                train_df = train_df.append(df)\n",
    "        #print(\"train_df : {} test_df : {}\".format(train_df.shape, test_df.shape))\n",
    "        train_users = set(train_df['uid'].unique())\n",
    "        test_users = set(test_df['uid'].unique())\n",
    "        common_users = train_users & test_users\n",
    "        #print(\"No of train_users  : \", len(train_users))\n",
    "        #print(\"No of test_users   : \", len(test_users))\n",
    "        #print(\"No of common_users : \", len(common_users))\n",
    "        #input()\n",
    "\n",
    "        train_X, train_y = train_df[features], train_df[target]    \n",
    "        #print(train_X.shape, train_y.shape)\n",
    "        test_X, test_y = test_df[features], test_df[target]\n",
    "        #print(test_X.shape, test_y.shape)\n",
    "\n",
    "        model = estimator.fit(train_X, train_y)\n",
    "\n",
    "        #predicted_train_y = model.predict(train_X)\n",
    "        #train_metrics = get_prediction_metrics(train_y, predicted_train_y)\n",
    "        #print(train_metrics)\n",
    "        predicted_test_y = model.predict(test_X)\n",
    "        test_metrics = get_prediction_metrics(test_y, predicted_test_y)\n",
    "        #print(test_metrics)\n",
    "        kfold_test_metrics.append(test_metrics)\n",
    "    #print(kfold_test_metrics)\n",
    "    avg_metrics = get_avg_test_metrics(kfold_test_metrics)\n",
    "    #print('r2 : {:05.4f}, mae : {:05.4f}, rmse : {:05.4f}'.format(avg_metrics['r2_score'], \n",
    "    #                                                 avg_metrics['mean_absolute_error'],\n",
    "    #                                                 avg_metrics['rmse']))\n",
    "    #print(avg_metrics)\n",
    "    #print('*'*40)\n",
    "    return avg_metrics\n",
    "\n",
    "# def get_train_test_metrics(estimator, training_df, testing_df):\n",
    "#     results = dict()\n",
    "#     results['train'] = get_avg_metrics(estimator, training_df)\n",
    "#     results['test'] = get_avg_metrics(estimator, testing_df)\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression                         RMSE : 0.6918\n",
      "Ridge                                    RMSE : 0.6918\n",
      "Lasso                                    RMSE : 0.8219\n",
      "ElasticNet                               RMSE : 0.8219\n",
      "SGDRegressor                             RMSE : 0.6983\n",
      "RandomForestRegressor                    RMSE : 0.7363\n",
      "GradientBoostingRegressor                RMSE : 0.6898\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "#Knn_UserBased_Baseline_SGD_Tuned                                      0.6956\n",
    "#                                                                      0.6946\n",
    "\n",
    "default_models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(),\n",
    "    Lasso(),\n",
    "    ElasticNet(),\n",
    "    SGDRegressor(max_iter=1000, tol=1e-3),\n",
    "    RandomForestRegressor(),\n",
    "    GradientBoostingRegressor()\n",
    "]\n",
    "for model in default_models:\n",
    "    #results = get_train_test_metrics(model, training_kfold_dfs, testing_kfold_dfs)    \n",
    "    #print(\"{:40s} Train RMSE : {}, Test RMSE : {}\".format(type(model).__name__, \n",
    "    #                                                      results['train']['rmse'],\n",
    "    #                                                      results['test']['rmse']))\n",
    "    results = get_avg_metrics(model, kfold_dfs)\n",
    "    print(\"{:40s} RMSE : {}\".format(type(model).__name__, results['rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression                         RMSE : 0.6918\n",
      "Ridge                                    RMSE : 0.6918\n",
      "Lasso                                    RMSE : 0.6918\n",
      "ElasticNet                               RMSE : 0.6921\n",
      "SGDRegressor                             RMSE : 0.696\n"
     ]
    }
   ],
   "source": [
    "tuned_models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(alpha=10),\n",
    "    Lasso(alpha=0.0001),\n",
    "    ElasticNet(alpha=0.01, l1_ratio=0.2),\n",
    "    SGDRegressor(alpha=0.0001, l1_ratio=0.1, loss='squared_loss', penalty='elasticnet', tol=0.0001),\n",
    "    #RandomForestRegressor(max_depth=15, n_estimators=150),\n",
    "    #GradientBoostingRegressor(learning_rate=0.1, max_depth=7, n_estimators=100)\n",
    "]\n",
    "for model in tuned_models:\n",
    "    #results = get_train_test_metrics(model, training_kfold_dfs, testing_kfold_dfs)\n",
    "    #print(\"{:40s} Train RMSE : {}, Test RMSE : {}\".format(type(model).__name__, \n",
    "    #                                                      results['train']['rmse'],\n",
    "    #                                                      results['test']['rmse']))\n",
    "    results = get_avg_metrics(model, kfold_dfs)\n",
    "    print(\"{:40s} RMSE : {}\".format(type(model).__name__, results['rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor                Train RMSE : 0.7373, Test RMSE : 0.7365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "model = SVR()\n",
    "\n",
    "results = get_train_test_metrics(SVR(), training_kfold_dfs, testing_kfold_dfs)\n",
    "print(\"{:40s} Train RMSE : {}, Test RMSE : {}\".format(type(model).__name__, \n",
    "                                                      results['train']['rmse'],\n",
    "                                                      results['test']['rmse']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
