{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8475, 10)\n",
      "(8475, 10)\n",
      "(8475, 10)\n",
      "(8475, 10)\n",
      "(8475, 10)\n",
      "(8475, 10)\n",
      "(8475, 10)\n",
      "(8475, 10)\n",
      "(8475, 10)\n",
      "(8475, 10)\n",
      "(84750, 10)\n",
      "(4710, 10)\n",
      "(4710, 10)\n",
      "(4710, 10)\n",
      "(4710, 10)\n",
      "(4710, 10)\n",
      "(4710, 10)\n",
      "(4710, 10)\n",
      "(4710, 10)\n",
      "(4705, 10)\n",
      "(4705, 10)\n",
      "(47090, 10)\n"
     ]
    }
   ],
   "source": [
    "no_of_kfolds = 10\n",
    "\n",
    "#load_kfold_dfs,all_dfs\n",
    "training_all_dfs = pd.DataFrame()\n",
    "training_kfold_dfs = dict()\n",
    "for kfold in range(1, no_of_kfolds+1):\n",
    "    df = pd.read_csv('hybrid_recommender/training_data/combined_predictions_' + str(kfold) + '.csv')\n",
    "    training_kfold_dfs[kfold] = df\n",
    "    training_all_dfs = training_all_dfs.append(df)\n",
    "    print(training_kfold_dfs[kfold].shape)\n",
    "print(training_all_dfs.shape)\n",
    "training_all_dfs.to_csv('hybrid_recommender/training_data/all_combined_predictions.csv', index=False)\n",
    "\n",
    "\n",
    "testing_all_dfs = pd.DataFrame()\n",
    "testing_kfold_dfs = dict()\n",
    "for kfold in range(1, no_of_kfolds+1):\n",
    "    df = pd.read_csv('hybrid_recommender/testing_data/combined_predictions_' + str(kfold) + '.csv')\n",
    "    testing_kfold_dfs[kfold] = df\n",
    "    testing_all_dfs = testing_all_dfs.append(df)\n",
    "    print(testing_kfold_dfs[kfold].shape)\n",
    "print(testing_all_dfs.shape)\n",
    "testing_all_dfs.to_csv('hybrid_recommender/testing_data/all_combined_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "features = ['BaselineOnly_SGD_Tuned_est',\n",
    "            'Knn_UserBased_ZScore_MSD_Tuned_est',\n",
    "            'Knn_ItemBased_ZScore_MSD_Tuned_est',\n",
    "            'Knn_UserBased_Baseline_SGD_Tuned_est',\n",
    "            'Knn_ItemBased_Baseline_SGD_Tuned_est', \n",
    "            'SVD_biased_Tuned_est',\n",
    "            'SVDpp_biased_Tuned_est']\n",
    "target = 'r_ui'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prediction_metrics(y_true, y_pred):\n",
    "    metrics = dict()\n",
    "    metrics['r2_score'] = r2_score(y_true, y_pred)\n",
    "    metrics['mean_absolute_error'] = mean_absolute_error(y_true, y_pred)\n",
    "    metrics['rmse'] = sqrt(mean_squared_error(y_true, y_pred))\n",
    "    return metrics\n",
    "\n",
    "def get_avg_test_metrics(kfold_test_metrics):\n",
    "    metrics = dict()\n",
    "    metrics['r2_score'] = []\n",
    "    metrics['mean_absolute_error'] = []\n",
    "    metrics['rmse'] = []\n",
    "    \n",
    "    for test_metrics in kfold_test_metrics:\n",
    "        metrics['r2_score'].append(test_metrics['r2_score'])\n",
    "        metrics['mean_absolute_error'].append(test_metrics['mean_absolute_error'])\n",
    "        metrics['rmse'].append(test_metrics['rmse'])\n",
    "    #print(metrics)\n",
    "    avg_metrics = dict()\n",
    "    avg_metrics['r2_score'] = round(np.mean(metrics['r2_score']), 4)\n",
    "    avg_metrics['mean_absolute_error'] = round(np.mean(metrics['mean_absolute_error']), 4)\n",
    "    avg_metrics['rmse'] = round(np.mean(metrics['rmse']), 4)\n",
    "    return avg_metrics\n",
    "\n",
    "def get_avg_metrics(estimator, kfold_dfs):\n",
    "    print(estimator)\n",
    "    kfold_test_metrics = []\n",
    "    for kfold in range(1, no_of_kfolds+1):\n",
    "        #print('*'*40)\n",
    "        #print('kfold_', str(kfold))\n",
    "        train_df = pd.DataFrame()\n",
    "        test_df = pd.DataFrame()\n",
    "        for kfold_id, df in kfold_dfs.items():\n",
    "            if kfold == kfold_id:\n",
    "                test_df = df\n",
    "            else:\n",
    "                train_df = train_df.append(df)\n",
    "        #print(\"train_df : {} test_df : {}\".format(train_df.shape, test_df.shape))\n",
    "        train_users = set(train_df['uid'].unique())\n",
    "        test_users = set(test_df['uid'].unique())\n",
    "        common_users = train_users & test_users\n",
    "        #print(\"No of train_users  : \", len(train_users))\n",
    "        #print(\"No of test_users   : \", len(test_users))\n",
    "        #print(\"No of common_users : \", len(common_users))\n",
    "\n",
    "        train_X, train_y = train_df[features], train_df[target]    \n",
    "        #print(train_X.shape, train_y.shape)\n",
    "        test_X, test_y = test_df[features], test_df[target]\n",
    "        #print(test_X.shape, test_y.shape)\n",
    "\n",
    "        model = estimator.fit(train_X, train_y)\n",
    "\n",
    "        #predicted_train_y = model.predict(train_X)\n",
    "        #train_metrics = get_prediction_metrics(train_y, predicted_train_y)\n",
    "        #print(train_metrics)\n",
    "        predicted_test_y = model.predict(test_X)\n",
    "        test_metrics = get_prediction_metrics(test_y, predicted_test_y)\n",
    "        #print(test_metrics)\n",
    "        kfold_test_metrics.append(test_metrics)\n",
    "    #print(kfold_test_metrics)\n",
    "    avg_metrics = get_avg_test_metrics(kfold_test_metrics)\n",
    "    print('r2 : {:05.4f}, mae : {:05.4f}, rmse : {:05.4f}'.format(avg_metrics['r2_score'], \n",
    "                                                     avg_metrics['mean_absolute_error'],\n",
    "                                                     avg_metrics['rmse']))\n",
    "    #print(avg_metrics)\n",
    "    print('*'*40)\n",
    "    return avg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation data\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "r2 : 0.2935, mae : 0.5532, rmse : 0.6910\n",
      "****************************************\n",
      "testing data\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "r2 : 0.2630, mae : 0.5545, rmse : 0.6912\n",
      "****************************************\n",
      "\n",
      "validation data\n",
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "r2 : 0.2935, mae : 0.5532, rmse : 0.6910\n",
      "****************************************\n",
      "testing data\n",
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "r2 : 0.2630, mae : 0.5545, rmse : 0.6912\n",
      "****************************************\n",
      "\n",
      "validation data\n",
      "Ridge(alpha=10, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "r2 : 0.2935, mae : 0.5532, rmse : 0.6910\n",
      "****************************************\n",
      "testing data\n",
      "Ridge(alpha=10, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "r2 : 0.2630, mae : 0.5545, rmse : 0.6912\n",
      "****************************************\n",
      "\n",
      "validation data\n",
      "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "r2 : -0.0014, mae : 0.7476, rmse : 0.8229\n",
      "****************************************\n",
      "testing data\n",
      "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "r2 : -0.0338, mae : 0.7492, rmse : 0.8219\n",
      "****************************************\n",
      "\n",
      "validation data\n",
      "Lasso(alpha=0.0001, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "r2 : 0.2935, mae : 0.5533, rmse : 0.6910\n",
      "****************************************\n",
      "testing data\n",
      "Lasso(alpha=0.0001, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "r2 : 0.2630, mae : 0.5545, rmse : 0.6912\n",
      "****************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "#Knn_UserBased_Baseline_SGD_Tuned                                      0.6948\n",
    "#                                                                      0.6946\n",
    "\n",
    "print(\"validation data\")\n",
    "get_avg_metrics(LinearRegression(), training_kfold_dfs)       #'rmse': 0.6910\n",
    "print(\"testing data\")\n",
    "get_avg_metrics(LinearRegression(), testing_kfold_dfs)        #'rmse': 0.6912\n",
    "print()\n",
    "\n",
    "# print(\"validation data\")\n",
    "# get_avg_metrics(Ridge(), training_kfold_dfs)                #'rmse': 0.6910\n",
    "# print(\"testing data\")\n",
    "# get_avg_metrics(Ridge(), testing_kfold_dfs)                 #'rmse': 0.6912\n",
    "# print()\n",
    "\n",
    "print(\"validation data\")\n",
    "get_avg_metrics(Ridge(alpha=10), training_kfold_dfs)          #'rmse': 0.6910\n",
    "print(\"testing data\")\n",
    "get_avg_metrics(Ridge(alpha=10), testing_kfold_dfs)           #'rmse': 0.6912\n",
    "print()\n",
    "\n",
    "\n",
    "# print(\"validation data\")\n",
    "# get_avg_metrics(Lasso(), training_kfold_dfs)                #'rmse': 0.8229\n",
    "# print(\"testing data\")\n",
    "# get_avg_metrics(Lasso(), testing_kfold_dfs)                 #'rmse': 0.8219\n",
    "# print()\n",
    "\n",
    "print(\"validation data\")\n",
    "get_avg_metrics(Lasso(alpha=0.0001), training_kfold_dfs)      #'rmse': 0.6910\n",
    "print(\"testing data\")\n",
    "get_avg_metrics(Lasso(alpha=0.0001), testing_kfold_dfs)       #'rmse': 0.6912\n",
    "print()\n",
    "\n",
    "\n",
    "#get_avg_metrics(ElasticNet(), training_kfold_dfs)\n",
    "#get_avg_metrics(SGDRegressor(), training_kfold_dfs)\n",
    "\n",
    "#get_avg_metrics(RandomForestRegressor(), training_kfold_dfs)\n",
    "#get_avg_metrics(GradientBoostingRegressor(), training_kfold_dfs)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVR\n",
    "# get_avg_metrics(SVR())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
